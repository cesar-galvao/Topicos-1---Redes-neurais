plot_grid(plot_residuos, plot_esperanca, ncol=2)
#| label: fig-esperado-observado
dados_graf_residuos %>%
ggplot(aes(yhat, y))+
geom_point(alpha = 0.3)+
geom_abline(slope = 1, intercept = 0, color = "red")+
theme_bw()+
labs(x = TeX("$\\hat{y}_i$"), y = TeX("$y_i$"))+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
#| label: gradiente-k
theta <- list(
M1 = matrix(c(0.1), nrow = 2, ncol = 2),
b12 = c(0.1, 0.1),
M2 = matrix(c(0.1), nrow = 2, ncol = 1),
b3 = c(0.1)
)
k_w1 <- function(dados, theta, i){
base <- dados[1:i,c(1, 2)] #dados com linha 1 ate i
y <- dados$y[1:i] #target com linhas 1 até i
return(gradiente(base, theta, y)$grad[1]) #retorna w1
}
valores_w1 <- tibble(
k = 1:300,
w1 = map_dbl(k, ~ k_w1(dados, theta, .))
)
#| label: fig-gradientek
ggplot(valores_w1, aes(k, w1, group = 1))+
geom_line()+
geom_hline(yintercept = grad_item_d["w1"], color = "red")+
theme_bw()+
labs(x = "Tamanho da amostra", y = TeX("$w_1$"))+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))+
annotate("text", x = 200, y = 0,
label = paste0("w1 = ",round(grad_item_d["w1"],2)),
hjust = 1, vjust = 0, size = 4, color = "red")
#| label: microbenchmark-gradiente
res <- microbenchmark::microbenchmark(
k_300 = k_w1(dados, theta, 300),
k_100000 = k_w1(dados, theta, 100000),
times = 100
)
#| label: ajuste-linear
dados_train
MSE1 <- lm(y ~ x1.obs + x2.obs, data = dados_train) %>%
anova() %>%
pull(`Mean Sq`) %>%
min()
MSE2 <- lm(y ~ x1.obs*x2.obs + I(x1.obs^2) + I(x2.obs^2), data = dados_train) %>%
anova() %>%
pull(`Mean Sq`) %>%
min()
#| label: tbl-MSE
tibble(
Modelo = c("Rede Neural", "Modelo Linear 1", "Modelo Linear 2"),
MSE = c(min(back_validacao$loss_history), MSE1, MSE2)
) %>%
mutate(MSE = round(MSE, 2)) %>%
knitr::kable()
lm(y ~ x1.obs + x2.obs, data = dados_train) %>%
anova()
lm(y ~ x1.obs + x2.obs, data = dados_train) %>%
summary()
lm(y ~ x1.obs + x2.obs, data = dados_train) %>%
summary() %>% class
lm(y ~ x1.obs + x2.obs, data = dados_train) %>%
summary() %>% tidy
back_validacao$best_theta
x1m1 <- lm(y ~ x1.obs + x2.obs, data = dados_train) %>%
summary() %>%
tidy()
x1m2 <-  lm(y ~ x1.obs*x2.obs + I(x1.obs^2) + I(x2.obs^2), data = dados_train) %>%
summary() %>%
tidy()
x1m1
x1m1$estimate[2]
x1m2
x2rn
x2rn <- back_validacao$best_theta$W1
x2rn
x2rn[1,]
#| label: setup
#| echo: false
pacman::p_load(tidyverse, NeuralNetTools,latex2exp, cowplot, microbenchmark, tidymodels)
#| label: efeito-x1
#| echo: false
x1m1 <- lm(y ~ x1.obs + x2.obs, data = dados_train)
x1m2 <-  lm(y ~ x1.obs*x2.obs + I(x1.obs^2) + I(x2.obs^2), data = dados_train)
x2rn <- back_validacao$best_theta$W1
x1m1 %>% summary() %>% tidy())$estimate[2]
(x1m1 %>% summary() %>% tidy())$estimate[2]
predict(x1m1, interval="prediction")
?between
#| label: setup
#| echo: false
pacman::p_load(tidyverse, NeuralNetTools,latex2exp, cowplot, microbenchmark, tidymodels)
predict(x1m1, interval="prediction") %>% dim()
?predict
predict(x1m1, interval="prediction", data = dados_test)
predict(x1m1, interval="prediction", data = dados_test) %>%
mutate(captura = ifelse(y >= lwr & y <= upr, 1, 0)) %>%
pull(captura) %>%
mean()
predict(x1m1, interval="prediction", data = dados_test) %>%
tidy() %>% glimpse()
predict(x1m1, interval="prediction", data = dados_test) %>%
tidy() %>% head()
predict(x1m1, interval="prediction", data = dados_test) %>%
tidy()
predict(x1m1, interval="prediction", data = dados_test) %>%
tidy() %>% head()
predict(x1m1, interval="prediction", data = dados_test) %>%
tidy() %>% head()
predictm1 <- predict(x1m1, interval="prediction", data = dados_test) %>%
tidy()
predictm1 <- predict(x1m1, interval="prediction", data = dados_test) %>%
tidy()
predictm1
dados_test$y %>% between(predictm1[,2], predictm1[,3]) %>% mean()
predictm1 <- predict(x1m1, interval="prediction", data = dados_test) %>%
tidy()
predictm1
?predict
predictm1 <- predict(x1m1, interval="prediction", newdata = dados_test) %>%
tidy()
head(predictm1)
predictm1
glimpse(dados_test)
View(predictm1)
dim(predictm1)
predictm1 %>% as.matrix(ncol = 3)
predictm1 <- predict(x1m1, interval="prediction", newdata = dados_test) %>%
tidy() %>%
as.matrix(ncol = 3)
dados_test$y %>% between(predictm1[,1], predictm1[,2])
dados_test$y >= predictm1[,1]
dados_test$y >= predictm1[,2] & dados_test$y <= predictm1[,3]
dados_test$y >= predictm1[,2] & dados_test$y <= predictm1[,3] %>%
mean()
(dados_test$y >= predictm1[,2] & dados_test$y <= predictm1[,3]) %>%
mean()
predictm2 <- predict(x1m2, interval="prediction", data = dados_test) %>%
tidy() %>%
as.matrix(ncol = 3)
(dados_test$y >= predictm2[,2] & dados_test$y <= predictm2[,3]) %>%
mean()
# rede neural
yhat <- ffwd(dados_test[,c(1,2)], back_validacao$best_theta)
View(yhat)
qnorm(0.972)
qnorm(0.975)
# rede neural
tabela_intervalo_rede <- tibble(
yhat = ffwd(dados_test[,c(1,2)], back_validacao$best_theta)$yhat,
sigma = sqrt(min(back_validacao$loss_history)),
std_y = (dados_test$y-yhat)/sigma
)
View(tabela_intervalo_rede)
# rede neural
tabela_intervalo_rede <- tibble(
yhat = ffwd(dados_test[,c(1,2)], back_validacao$best_theta)$yhat,
sigma = sqrt(min(back_validacao$loss_history)),
y = dados_test$y,
std_y = (y-yhat)/sigma
)
# rede neural
tabela_intervalo_rede <- tibble(
yhat = ffwd(dados_test[,c(1,2)], back_validacao$best_theta)$yhat,
sigma = sqrt(min(back_validacao$loss_history)),
y = dados_test$y,
std_y = (y-yhat)/sigma
) %>%
mutate(
lower = yhat - 1.96*sigma,
upper = yhat + 1.96*sigma,
within = (y >= lower & y <= upper)
)
tibble(
yhat = ffwd(dados_test[,c(1,2)], back_validacao$best_theta)$yhat,
sigma = sqrt(min(back_validacao$loss_history)),
y = dados_test$y,
std_y = (y-yhat)/sigma
) %>%
mutate(
lower = yhat - 1.96*sigma,
upper = yhat + 1.96*sigma,
within = (y >= lower & y <= upper)
) %>%
pull(within) %>%
mean()
withinrn <- tabela_intervalo_rede %>%
pull(within) %>%
mean()
MSErn <- min(back_validacao$loss_history)
tibble(
Modelo = c("Rede Neural", "Modelo Linear 1", "Modelo Linear 2"),
MSE = c(MSErn, MSE1, MSE2)
) %>%
mutate(MSE = round(MSE, 2)) %>%
knitr::kable()
tibble(
Modelo = c("Modelo Linear 1", "Modelo Linear 2", "Rede Neural"),
Proporção = c(withinm1, withinm2, withinrn)
) %>%
knitr::kable(digits = 2)
#| label: intervalos-confianca
# modelo 1
predictm1 <- predict(x1m1, interval="prediction", newdata = dados_test) %>%
tidy() %>%
as.matrix(ncol = 3)
withinm1 <- (dados_test$y >= predictm1[,2] & dados_test$y <= predictm1[,3]) %>%
mean()
# modelo 2
predictm2 <- predict(x1m2, interval="prediction", data = dados_test) %>%
tidy() %>%
as.matrix(ncol = 3)
withinm2 <- (dados_test$y >= predictm2[,2] & dados_test$y <= predictm2[,3]) %>%
mean()
# rede neural
tabela_intervalo_rede <- tibble(
yhat = ffwd(dados_test[,c(1,2)], back_validacao$best_theta)$yhat,
sigma = sqrt(min(back_validacao$loss_history)),
y = dados_test$y,
std_y = (y-yhat)/sigma
) %>%
mutate(
lower = yhat - 1.96*sigma,
upper = yhat + 1.96*sigma,
within = (y >= lower & y <= upper)
)
withinrn <- tabela_intervalo_rede %>%
pull(within) %>%
mean()
#| label: tbl-intervalos-confianca
#| echo: false
tibble(
Modelo = c("Modelo Linear 1", "Modelo Linear 2", "Rede Neural"),
Proporção = c(withinm1, withinm2, withinrn)
) %>%
knitr::kable(digits = 2)
)
tibble(
Modelo = c("Modelo Linear 1", "Modelo Linear 2", "Rede Neural"),
Proporção = c(withinm1, withinm2, withinrn)
) %>%
knitr::kable(digits = 2)
tibble(
Modelo = c("Modelo Linear 1", "Modelo Linear 2", "Rede Neural"),
Proporção = c(withinm1, withinm2, withinrn),
MSE = c(MSErn, MSE1, MSE2)
) %>%
knitr::kable(digits = 2)
tibble(
Modelo = c("Modelo Linear 1", "Modelo Linear 2", "Rede Neural"),
Proporção = c(withinm1, withinm2, withinrn),
MSE = c(MSE1, MSE2,MSErn)
) %>%
knitr::kable(digits = 2)
back_validacao$loss_history %>%
tibble(Iteracao = 1:length(.), Custo = .) %>%
filter(custo > 170) %>%
ggplot(aes(x = Iteracao, y = Custo)) +
geom_line() +
labs(x = "Iteração",
y = "Custo")+
theme_bw()+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm")) # Control tick length
back_validacao$loss_history %>%
tibble(Iteracao = 1:length(.), Custo = .) %>%
filter(Custo > 170) %>%
ggplot(aes(x = Iteracao, y = Custo)) +
geom_line() +
labs(x = "Iteração",
y = "Custo")+
theme_bw()+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm")) # Control tick length
back_validacao$loss_history %>%
tibble(Iteracao = 1:length(.), Custo = .)
back_validacao$loss_history %>%
tibble(Iteracao = 1:length(.), Custo = .) %>%
filter(Custo < 170) %>%
ggplot(aes(x = Iteracao, y = Custo)) +
geom_line() +
labs(x = "Iteração",
y = "Custo")+
theme_bw()+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm")) # Control tick length
microbenchmark::microbenchmark(
k_300 = k_w1(dados, theta, 300),
k_100000 = k_w1(dados, theta, 100000),
times = 100
)
microbenchmark::microbenchmark(
k_300 = k_w1(dados, theta, 300),
k_100000 = k_w1(dados, theta, 100000),
times = 100
) %>% summary
?kable
microbenchmark::microbenchmark(
k_300 = k_w1(dados, theta, 300),
k_100000 = k_w1(dados, theta, 100000),
times = 100
)
x1m1 <- lm(y ~ x1.obs + x2.obs, data = dados_train)
x1m2 <-  lm(y ~ x1.obs*x2.obs + I(x1.obs^2) + I(x2.obs^2), data = dados_train)
x2rn <- back_validacao$best_theta$W1
(x1m1 %>% summary() %>% tidy())$estimate[2]
(x1m2 %>% summary() %>% tidy())$estimate[2]
(x1m1 %>% summary() %>% tidy())$estimate[4]
predict(x1m1, interval="prediction", newdata = dados_test) %>%
tidy() %>%
as.matrix(ncol = 3)
(dados_test$y >= predictm1[,2] & dados_test$y <= predictm1[,3])
tibble(predictm1)
tibble(predictm1) %>%
rlang::set_names(c("yhat","lower", "upper")) %>%
mutate(y = dados_test$y,
within = (y >= lower & y <= upper))
glimpse(dados_test)
tibble(predictm1) %>%
rlang::set_names(c("yhat","lower", "upper")) %>%
mutate(y = dados_test$y)
tibble(predictm1) %>%
rlang::set_names(c("yhat","lower", "upper"))
tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper") %>%
mutate(y = dados_test$y)
tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper")
tibble(predictm1) %>% names()
tibble(predictm1) %>% glimpse()
as_tibble(predictm1) %>% glimpse()
as_tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper") %>%
mutate(y = dados_test$y)
as_tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper") %>%
mutate(y = dados_test$y,
within = (y >= lower & y <= upper))
as_tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper") %>%
mutate(y = dados_test$y,
within = (y >= lower & y <= upper),
x1 = dados_test$x1.obs,
x2 = dados_test$x2.obs)
tabela <- as_tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper") %>%
mutate(y = dados_test$y,
within = (y >= lower & y <= upper),
x1 = dados_test$x1.obs,
x2 = dados_test$x2.obs)
tabela$within %>% mean
tabela <- as_tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper") %>%
mutate(y = dados_test$y,
within = (y >= lower & y <= upper),
x1 = dados_test$x1.obs,
x2 = dados_test$x2.obs)
ggplot(tabela, aes(x1, x2, color = within))+
geom_point()
ggplot(tabela, aes(x1, x2, color = within))+
geom_point(alpha = 0.3)
ggplot(tabela, aes(x1, x2, color = within))+
geom_point(alpha = 0.3)+
theme_bw()+
labs(x = "Tamanho da amostra", y = TeX("$w_1$"))+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
ggplot(tabela, aes(x1, x2, color = within))+
geom_point(alpha = 0.3)+
theme_bw()+
labs(x = TeX("$x_1$"), y = TeX("$x_2$"), color = "Dentro do IC")+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
# rede neural
tabela_withinrn <- tibble(
yhat = ffwd(dados_test[,c(1,2)], back_validacao$best_theta)$yhat,
sigma = sqrt(min(back_validacao$loss_history)),
y = dados_test$y,
std_y = (y-yhat)/sigma
) %>%
mutate(
lower = yhat - 1.96*sigma,
upper = yhat + 1.96*sigma,
within = (y >= lower & y <= upper)
)
tabela_withinrn
tabela_withinrn %>%
mutate(x1 = dados_test$x1.obs,
x2 = dados_test$x2.obs) %>%
ggplot(aes(x1, x2, color = within))+
geom_point(alpha = 0.09)+
theme_bw()+
labs(x = TeX("$x_1$"), y = TeX("$x_2$"), color = "Dentro do IC")+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
#| label: fig-intervaloconfiancarede
#| fig-cap: Pontos contidos nos intervalos de confiança de 95% para a Rede Neural.
tabela_withinrn %>%
mutate(x1 = dados_test$x1.obs,
x2 = dados_test$x2.obs) %>%
ggplot(aes(x1, x2, color = within))+
geom_point(alpha = 0.09)+
theme_bw()+
labs(x = TeX("$x_1$"), y = TeX("$x_2$"), color = "Dentro do IC")+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
plot_regressao <- ggplot(tabela, aes(x1, x2, color = within))+
geom_point(alpha = 0.09)+
theme_bw()+
labs(x = TeX("$x_1$"), y = TeX("$x_2$"), color = "Dentro do IC")+
scale_discrete_manual(values = c("TRUE" = "blue", "FALSE" = "red"))+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
plot_regressao <- ggplot(tabela, aes(x1, x2, color = within))+
geom_point(alpha = 0.09)+
scale_color_manual(values = c("blue", "red")) +
theme_bw()+
labs(x = TeX("$x_1$"), y = TeX("$x_2$"), color = "Dentro do IC")+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
#| label: fig-intervaloconfianca
#| fig-cap: Pontos contidos nos intervalos de confiança de 95% para o Modelo Linear 1.
tabela <- as_tibble(predictm1) %>%
rlang::set_names("yhat","lower", "upper") %>%
mutate(y = dados_test$y,
within = (y >= lower & y <= upper),
x1 = dados_test$x1.obs,
x2 = dados_test$x2.obs)
plot_regressao <- ggplot(tabela, aes(x1, x2, color = within))+
geom_point(alpha = 0.09)+
scale_color_manual(values = c("blue", "red")) +
theme_bw()+
labs(x = TeX("$x_1$"), y = TeX("$x_2$"), color = "Dentro do IC")+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
plot_grid(plot_regressao, plot_esperanca, ncol=2)
#| label: fig-intervaloconfiancarede
#| fig-cap: Pontos contidos nos intervalos de confiança de 95% para a Rede Neural.
tabela_withinrn %>%
mutate(x1 = dados_test$x1.obs,
x2 = dados_test$x2.obs) %>%
ggplot(aes(x1, x2, color = within))+
scale_color_manual(values = c("green", "red")) +
geom_point(alpha = 0.12)+
theme_bw()+
labs(x = TeX("$x_1$"), y = TeX("$x_2$"), color = "Dentro do IC")+
theme(panel.border = element_blank(), # Remove all panel borders
axis.line = element_line(color = "#474747"), # Add axis lines
axis.ticks.x = element_line(color = "#474747"), # X axis ticks
axis.ticks.y = element_line(color = "#474747"), # Y axis ticks
axis.ticks.length = unit(0.05, "cm"), # Control tick length
legend.position = "bottom",
axis.title.y = element_text(angle = 0, vjust = 0.5))
